---
---

@string{aps = {American Physical Society,}}

@article{Li2017,
abstract = {The wide field of view (WFV) imaging system onboard the Chinese GaoFen-1 (GF-1) optical satellite has a 16-m resolution and four-day revisit cycle for large-scale Earth observation. The advantages of the high temporal-spatial resolution and the wide field of view make the GF-1 WFV imagery very popular. However, cloud cover is an inevitable problem in GF-1 WFV imagery, which influences its precise application. Accurate cloud and cloud shadow detection in GF-1 WFV imagery is quite difficult due to the fact that there are only three visible bands and one near-infrared band. In this paper, an automatic multi-feature combined (MFC) method is proposed for cloud and cloud shadow detection in GF-1 WFV imagery. The MFC algorithm first implements threshold segmentation based on the spectral features and mask refinement based on guided filtering to generate a preliminary cloud mask. The geometric features are then used in combination with the texture features to improve the cloud detection results and produce the final cloud mask. Finally, the cloud shadow mask can be acquired by means of the cloud and shadow matching and follow-up correction process. The method was validated using 108 globally distributed scenes. The results indicate that MFC performs well under most conditions, and the average overall accuracy of MFC cloud detection is as high as 96.8%. In the contrastive analysis with the official provided cloud fractions, MFC shows a significant improvement in cloud fraction estimation, and achieves a high accuracy for the cloud and cloud shadow detection in the GF-1 WFV imagery with fewer spectral bands. The proposed method could be used as a preprocessing step in the future to monitor land-cover change, and it could also be easily extended to other optical satellite imagery which has a similar spectral setting. The global validation dataset and the software tool used in this study have been made available online (http://sendimage.whu.edu.cn/en/mfc/).},
author = {Li, Zhiwei and Shen, Huanfeng and Li, Huifang and Xia, Guisong and Gamba, Paolo and Zhang, Liangpei},
doi = {10.1016/j.rse.2017.01.026},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Cloud detection,Cloud shadow,GF-1,MFC,Multiple features},
pages = {342--358},
title = {{Multi-feature combined cloud and cloud shadow detection in GaoFen-1 wide field of view imagery}},
volume = {191},
year = {2017}
}
@article{Li2022,
abstract = {The presence of clouds prevents optical satellite imaging systems from obtaining useful Earth observation information and negatively affects the processing and application of optical satellite images. Therefore, the detection of clouds and their accompanying shadows is an essential step in preprocessing optical satellite images and has emerged as a popular research topic in recent decades due to the interest in image time series analysis and remote sensing data mining. This review first analyzes the trends of the field, summarizes the progress and achievements in the cloud and cloud shadow detection methods in terms of features, algorithms, and validation of results, and then discusses existing problems, and provides our prospects at the end. We aim at identifying the emerging research trends and opportunities, while providing guidance for selecting the most suitable methods for coping with cloud contaminated problems faced by optical satellite images, an extremely important issue for remote sensing of cloudy and rainy areas. In the future, expected improvements in accuracy and generalizability, the combination of physical models and deep learning, as well as artificial intelligence and online big data processing platforms will be able to further promote processing efficiency and facilitate applications of image time series. In addition, this review collects the latest open-source tools and datasets for cloud and cloud shadow detection and launches an online project (Open Satellite Image Cloud Detection Resources, i.e., OpenSICDR) to share the latest research outputs (https://github.com/dr-lizhiwei/OpenSICDR).},
author = {Li, Zhiwei and Shen, Huanfeng and Weng, Qihao and Zhang, Yuzhuo and Dou, Peng and Zhang, Liangpei},
doi = {10.1016/j.isprsjprs.2022.03.020},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Cloud detection,Cloud shadow detection,Cloudy and rainy regions,Optical remote sensing,Satellite imagery},
month = {jun},
pages = {89--108},
publisher = {Elsevier},
title = {{Cloud and cloud shadow detection for optical satellite imagery: Features, algorithms, validation, and prospects}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0924271622000934},
volume = {188},
year = {2022}
}
@article{Zhang2021,
abstract = {The thick cloud coverage phenomenon severely disturbs optical satellite observation missions (covering approximately 40–60% areas in the global scale). Therefore, the manner by which to eliminate thick cloud in remote sensing imagery is greatly significant and indispensable. In this study, we combine the deep spatio-temporal prior with low-rank tensor singular value decomposition (DP-LRTSVD) for thick cloud removal in multitemporal images. On the one hand, DP-LRTSVD utilizes the low-rank characteristic of multitemporal images via the third-order tensor SVD and completion. On the other hand, DP-LRTSVD employs the deep spatio-temporal feature expression ability by 3D convolutional neural network. The proposed framework can effectively eliminate thick cloud in multitemporal images through combining the model-driven and data-driven strategies. Moreover, DP-LRTSVD outperforms on thick cloud removal in the simulated and real multitemporal Sentinel-2/GF-1 experiments compared with model-driven or data-driven methods. In contrast with most methods that can only use a single reference image for thick cloud removal, the proposed method can simultaneously eliminate thick cloud in time-series images.},
author = {Zhang, Qiang and Yuan, Qiangqiang and Li, Zhiwei and Sun, Fujun and Zhang, Liangpei},
doi = {10.1016/j.isprsjprs.2021.04.021},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Deep prior,Low-rank tensor SVD,Multitemporal images,Spatio-temporal,Thick cloud removal},
month = {jul},
pages = {161--173},
publisher = {Elsevier},
title = {{Combined deep prior with low-rank tensor SVD for thick cloud removal in multitemporal images}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0924271621001258},
volume = {177},
year = {2021}
}
@article{Dou2021a,
abstract = {Recently, classification using multiple classifier system (MCS) has been reported as an effective method to improve remote sensing (RS) image classification. Such systems provide a complementary mechanism to use multiple classifiers, which have shallow architecture to solve the same classification problem; however, the system exhibits shortcomings due to complex ensemble strategy. Deep learning (DL) has been proven to be an advanced method for complex data classification; however, how to use its advantages to overcome the shortcomings of MCS in ensemble strategy for classification accuracy improvement is worthy of study. Thus, with the multiple classifier mechanism and DL architecture, we propose a novel RS image classification framework, namely, deep-shallow learning (DSL), to improve classification accuracy. The DSL framework consists of a shallow learning (SL) layer and a DL layer. The SL layer contains various classifiers with shallow architecture, which can output different classification results for a certain input, whereas the DL layer is formed by DL networks, which can continue learning from the outputs of the SL layer. DSL simulates a human thinking model that continuously learns from the existing learnings to improve learning efficiency. In our experiment, three shallow classification algorithms, i.e., C4.5, k-nearest neighbor, and naive Bayesian, are used to train base classifiers in the SL layer, whereas a deep belief network (DBN) is used to train the DL layer. The experiment results on three different datasets indicate that DSL outperforms other methods in terms of classification accuracy by using backpropagation neural network, bagging, AdaBoost, random forest, multilayer perceptron, and DBN.},
author = {Dou, Peng and Shen, Huanfeng and Li, Zhiwei and Guan, Xiaobin and Huang, Wenli},
doi = {10.1109/JSTARS.2021.3062635},
issn = {21511535},
journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
keywords = {Deep-shallow learning (DSL),deep learning (DL),ensemble learning (EL),image classification,remote sensing (RS)},
pages = {3070--3083},
title = {{Remote Sensing Image Classification Using Deep-Shallow Learning}},
volume = {14},
year = {2021}
}
@article{Dou2021,
abstract = {Recently, time series image (TSI) has been reported to be an effective resource to mapping fine land use/land cover (LULC), and deep learning, in particular, has been gaining growing attention in this field. However, deep learning methods using single classifier need further improvement for accurate TSI classification owing to the 1D temporal properties and insufficient dense time series of the remote sensing images. To overcome such disadvantages, we proposed an innovative approach involving construction of TSI and combination of deep learning and multiple classifiers system (MCS). Firstly, we used a normalised difference index (NDI) to establish an NDIs-based TSI and then designed a framework consisting of a deep learning-based feature extractor and multiple classifiers system (MCS) based classification model to classify the TSI. With the new approach, our experiments were conducted on Landsat images located in two counties, Sutter and Kings in California, United States. The experimental results indicate that our proposed method achieves great progress on accuracy improvement and LULC mapping, outperforming classifications using comparative deep learning and non-deep learning methods.},
author = {Dou, Peng and Shen, Huanfeng and Li, Zhiwei and Guan, Xiaobin},
doi = {10.1016/j.jag.2021.102477},
issn = {1872826X},
journal = {International Journal of Applied Earth Observation and Geoinformation},
keywords = {Deep learning,Ensemble learning,Normalised differential index,Remote sensing image classification,Time series image classification},
pages = {102477},
publisher = {Elsevier},
title = {{Time series remote sensing image classification framework using combination of deep learning and multiple classifiers system}},
volume = {103},
year = {2021}
}
@article{Yuan2020,
abstract = {Various forms of machine learning (ML) methods have historically played a valuable role in environmental remote sensing research. With an increasing amount of “big data” from earth observation and rapid advances in ML, increasing opportunities for novel methods have emerged to aid in earth environmental monitoring. Over the last decade, a typical and state-of-the-art ML framework named deep learning (DL), which is developed from the traditional neural network (NN), has outperformed traditional models with considerable improvement in performance. Substantial progress in developing a DL methodology for a variety of earth science applications has been observed. Therefore, this review will concentrate on the use of the traditional NN and DL methods to advance the environmental remote sensing process. First, the potential of DL in environmental remote sensing, including land cover mapping, environmental parameter retrieval, data fusion and downscaling, and information reconstruction and prediction, will be analyzed. A typical network structure will then be introduced. Afterward, the applications of DL environmental monitoring in the atmosphere, vegetation, hydrology, air and land surface temperature, evapotranspiration, solar radiation, and ocean color are specifically reviewed. Finally, challenges and future perspectives will be comprehensively analyzed and discussed.},
author = {Yuan, Qiangqiang and Shen, Huanfeng and Li, Tongwen and Li, Zhiwei and Li, Shuwen and Jiang, Yun and Xu, Hongzhang and Tan, Weiwei and Yang, Qianqian and Wang, Jiwen and Gao, Jianhao and Zhang, Liangpei},
doi = {10.1016/j.rse.2020.111716},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Deep learning,Environmental remote sensing,Neural network,Parameter retrieval},
month = {may},
pages = {111716},
publisher = {Elsevier},
title = {{Deep learning in environmental remote sensing: Achievements and challenges}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0034425720300857},
volume = {241},
year = {2020}
}
@misc{Wang2019,
abstract = {Urban water is important for the urban ecosystem. Accurate and efficient detection of urban water with remote sensing data is of great significance for urban management and planning. In this article, we proposed a new method by combining Google Earth Engine (GEE) with a multiscale convolutional neural network (MSCNN) to extract urban water from Landsat images, which can be summarized as 'offline training and online prediction' (OTOP). That is, the training of MSCNN is completed offline, and the process of urban water extraction is implemented on GEE with the trained parameters of MSCNN. The OTOP can give full play to the respective advantages of GEE and the convolutional neural network (CNN), and can make the use of deep learning method in GEE more flexible. The proposed method can process the available satellite images with high performance, without data download and storage, and the overall performance of urban water extraction in the test areas is also higher than that of the modified normalized difference water index (MNDWI) and random forest classifier. The results of the extended validation in the other major cities of China also showed that OTOP is robust and can be used to extract different types of urban water, which benefits from the structural design and training of MSCNN. Therefore, OTOP is especially suitable for the study of large-scale and long-term urban water change detection in the background of urbanization.},
author = {Wang, Yudie and Li, Zhiwei and Zeng, Chao and Xia, Gui Song and Shen, Huanfeng},
booktitle = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
doi = {10.1109/JSTARS.2020.2971783},
issn = {21511535},
keywords = {Convolutional neural network,google earth engine,urban water,water extraction},
pages = {768--781},
title = {{An Urban Water Extraction Method Combining Deep Learning and Google Earth Engine}},
volume = {13},
year = {2020}
}
@article{Li2020,
abstract = {Urban geographical maps are important to urban planning, urban construction, land-use studies, disaster control and relief, touring and sightseeing, and so on. Satellite remote sensing images are the most important data source for urban geographical maps. However, for optical satellite remote sensing images with high spatial resolution, certain inevitable factors, including cloud, haze, and cloud shadow, severely degrade the image quality. Moreover, the geometrical and radiometric differences amongst multiple high-spatial-resolution images are difficult to eliminate. In this study, we propose a robust and efficient procedure for generating high-resolution and high-quality seamless satellite imagery for large-scale urban regions. This procedure consists of image registration, cloud detection, thin/thick cloud removal, pansharpening, and mosaicking processes. Methodologically, a spatially adaptive method considering the variation of atmospheric scattering, and a stepwise replacement method based on local moment matching are proposed for removing thin and thick clouds, respectively. The effectiveness is demonstrated by a successful case of generating a 0.91-m-resolution image of the main city zone in Nanning, Guangxi Zhuang Autonomous Region, China, using images obtained from the Chinese Beijing-2 and Gaofen-2 high-resolution satellites.},
author = {Li, Xinghua and Li, Zhiwei and Feng, Ruitao and Luo, Shuang and Zhang, Chi and Jiang, Menghui and Shen, Huanfeng},
doi = {10.3390/RS12010081},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Cloud detection and removal,High-quality and high-resolution,Mosaicking,Pansharpening,Remote sensing},
month = {dec},
number = {1},
pages = {81},
title = {{Generating high-quality and high-resolution seamless satellite imagery for large-scale urban regions}},
url = {https://www.mdpi.com/2072-4292/12/1/81},
volume = {12},
year = {2020}
}
@article{Li2019a,
abstract = {Cloud detection is an important preprocessing step for the precise application of optical satellite imagery. In this paper, we propose a deep learning based cloud detection method named multi-scale convolutional feature fusion (MSCFF) for remote sensing images of different sensors. In the network architecture of MSCFF, the symmetric encoder-decoder module, which provides both local and global context by densifying feature maps with trainable convolutional filter banks, is utilized to extract multi-scale and high-level spatial features. The feature maps of multiple scales are then up-sampled and concatenated, and a novel multi-scale feature fusion module is designed to fuse the features of different scales for the output. The two output feature maps of the network are cloud and cloud shadow maps, which are in turn fed to binary classifiers outside the model to obtain the final cloud and cloud shadow mask. The MSCFF method was validated on hundreds of globally distributed optical satellite images, with spatial resolutions ranging from 0.5 to 50 m, including Landsat-5/7/8, Gaofen-1/2/4, Sentinel-2, Ziyuan-3, CBERS-04, Huanjing-1, and collected high-resolution images exported from Google Earth. The experimental results show that MSCFF achieves a higher accuracy than the traditional rule-based cloud detection methods and the state-of-the-art deep learning models, especially in bright surface covered areas. The effectiveness of MSCFF means that it has great promise for the practical application of cloud detection for multiple types of medium and high-resolution remote sensing images. Our established global high-resolution cloud detection validation dataset has been made available online (http://sendimage.whu.edu.cn/en/mscff/).},
archivePrefix = {arXiv},
arxivId = {1810.05801},
author = {Li, Zhiwei and Shen, Huanfeng and Cheng, Qing and Liu, Yuhao and You, Shucheng and He, Zongyi},
doi = {10.1016/j.isprsjprs.2019.02.017},
eprint = {1810.05801},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Cloud detection,Cloud shadow,Convolutional feature fusion,Convolutional neural network,MSCFF,Multi-scale},
pages = {197--212},
title = {{Deep learning based cloud detection for medium and high resolution remote sensing images of different sensors}},
volume = {150},
year = {2019}
}
@article{Li2019,
abstract = {Cloud cover is a common problem in optical satellite imagery, which leads to missing information in images as well as a reduction in the data usability. In this paper, a thick cloud removal method based on stepwise radiometric adjustment and residual correction (SRARC) is proposed, which is aimed at effectively removing the clouds in high-resolution images for the generation of high-quality and spatially contiguous urban geographical maps. The basic idea of SRARC is that the complementary information in adjacent temporal satellite images can be utilized for the seamless recovery of cloud-contaminated areas in the target image after precise radiometric adjustment. To this end, the SRARC method first optimizes the given cloud mask of the target image based on superpixel segmentation, which is conducted to ensure that the labeled cloud boundaries go through homogeneous areas of the target image, to ensure a seamless reconstruction. Stepwise radiometric adjustment is then used to adjust the radiometric information of the complementary areas in the auxiliary image, step by step, and clouds in the target image can be removed by the replacement with the adjusted complementary areas. Finally, residual correction based on global optimization is used to further reduce the radiometric differences between the recovered areas and the cloud-free areas. The final cloud removal results are then generated. High-resolution images with different spatial resolutions and land-cover change patterns were used in both simulated and real-data cloud removal experiments. The results suggest that SRARC can achieve a better performance than the other compared methods, due to the superiority of the radiometric adjustment and spatial detail preservation. SRARC is thus a promising approach that has the potential for routine use, to support applications based on high-resolution satellite images.},
author = {Li, Zhiwei and Shen, Huanfeng and Cheng, Qing and Li, Wei and Zhang, Liangpei},
doi = {10.3390/rs11161925},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Cloud removal,High-resolution images,Multi-temporal,Residual correction,SRARC,Stepwise radiometric adjustment},
month = {aug},
number = {16},
pages = {1925},
title = {{Thick cloud removal in high-resolution satellite images using stepwise radiometric adjustment and residual correction}},
url = {https://www.mdpi.com/2072-4292/11/16/1925},
volume = {11},
year = {2019}
}
