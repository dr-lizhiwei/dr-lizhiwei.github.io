<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://zhiweili.net//feed.xml" rel="self" type="application/atom+xml"/><link href="https://zhiweili.net//" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-10T20:48:55+00:00</updated><id>https://zhiweili.net//feed.xml</id><title type="html">Dr. Zhiwei Li - Homepage</title><subtitle>Zhiwei Li, Ph.D. (李志伟 博士), Research Assistant Professor, Department of Land Surveying and Geo-Informatics (LSGI), The Hong Kong Polytechnic University (PolyU), 香港理工大学. </subtitle><entry><title type="html">多云地区时间序列土地利用/覆盖制图 [in Chinese]</title><link href="https://zhiweili.net//blog/2024/lulc-mapping-CHN/" rel="alternate" type="text/html" title="多云地区时间序列土地利用/覆盖制图 [in Chinese]"/><published>2024-06-05T00:00:00+00:00</published><updated>2024-06-05T00:00:00+00:00</updated><id>https://zhiweili.net//blog/2024/lulc-mapping-CHN</id><content type="html" xml:base="https://zhiweili.net//blog/2024/lulc-mapping-CHN/"><![CDATA[<p>Li, Z., Weng, Q., Zhou, Y., Dou, P., &amp; Ding, X. (2024). Learning spectral-indices-fused deep models for time-series land use and land cover mapping in cloud-prone areas: The case of Pearl River Delta. <em>Remote Sensing of Environment</em>, 308, 114190. [<a href="https://doi.org/10.1016/j.rse.2024.114190">HTML</a>] <a href="https://zhiweili.net/assets/pdf/2024.7_RSE_Learning%20spectral-indices-fused%20deep%20models%20for%20time-series%20land%20use%20and%20land%20cover%20mapping%20in%20cloud-prone%20areas.pdf">[PDF]</a></p> <h4 id="亮点"><strong>亮点</strong></h4> <ul> <li>提出了一种结合深度学习模型和时间序列重建的新颖土地利用与覆盖（LULC）制图方法。</li> <li>在多云和多雨地区（珠三角）实现高时间密度的10米无缝LULC制图。</li> <li>2019-2022年期间，年度制图平均总体精度高达87.01%，优于现有的LULC产品。</li> <li>具有生成无缝近实时分类图和高质量的月度、季度和年度LULC数据集的潜力。</li> </ul> <h4 id="摘要"><strong>摘要</strong></h4> <p>使用光学卫星影像进行土地利用和土地覆盖（LULC）动态变化制图可能受到各种云雨天气条件的干扰，这些干扰会导致高时间密度的LULC制图存在空间不连续问题。本研究开发了一种集成的时间序列LULC制图方法，通过结合光谱指数融合的深度学习模型和时间序列重建技术，来提高多云地区LULC制图的精度和频次。该方法首先通过时间序列滤波重建受云污染的像元，在此过程中，由深度模型初始化生成的云掩膜在重建过程中得到优化和更新。然后，将重建的时间序列影像输入到一个基于全球范围收集的样本训练的光谱指数融合深度模型中进行分类。最后，进行分类后处理，包括时空众数滤波和考虑水陆交互的时间序列优化，以提高LULC制图的准确性和一致性。本研究将该方法应用于多云多雨的珠三角地区（即粤港澳大湾区），并使用Sentinel-2时间序列影像作为实验数据。该方法实现了2-5天时间频次的无缝LULC制图，并生成了大湾区地区10米分辨率的年度LULC产品。评估结果显示，2019-2022年连续四年的年度制图的平均总体精度为87.01%，优于现有LULC产品，包括ESA WorldCover (83.98%)、Esri Land Cover (85.26%)和Google Dynamic World (85.06%)。本研究的评估结果还显示了应用不同云掩膜情况下LULC制图精度的显著差异，强调了它们在时间序列LULC制图中的关键作用。该方法有望通过使用全球数据集训练的深度模型为世界范围其它地区生成无缝和近实时的土地利用和土地覆盖图。这一方法可以在不同时间间隔内为多云和多雨地区的各种土地和水体动态提供高质量的LULC数据集。尽管在多云地区获得高质量LULC数据具有挑战性，本研究为LULC动态制图和提供可靠的年度LULC产品提供了一种新方法。</p> <h4 id="1-研究背景"><strong>1.</strong> <strong>研究背景</strong></h4> <p>土地利用和土地覆盖（LULC）数据集在土地利用规划和管理、生态环境保护以及农业等应用中起着至关重要的作用。LULC制图一直是一个热门的研究课题，并且随着数据获取和处理能力的进步不断发展。在过去的几十年里，LULC制图的空间分辨率从中分辨率提高到高分辨率，达到了米级甚至亚米级。同时，LULC制图的时间频次也从年度制图提升到近实时制图。最近的机器学习技术，特别是深度学习，极大程度地革新了LULC制图领域，并广泛用于生产新的区域和全球LULC产品。上述方面的LULC制图进展标志着在实现基于密集时间序列影像的精确和连续LULC制图方面取得了重要成果。</p> <p>尽管如此，在LULC制图领域仍存在两个主要问题。一方面，光学时间序列影像数据中的云覆盖降低了时间序列LULC制图中的数据可用性。同时，精确的云掩膜对于高时间密度近实时LULC制图尤其是在多云地区的重要性不容忽视。然而，常用的云掩膜往往不够精确，仍有进一步改进的空间，这在最近的多项研究中得到了证实。特别是对于Sentinel-2影像，Sentinel-2 Level 1-C云掩膜产品被发现普遍低估了云的存在，这是不可忽视的。其它现有的云检测方法，如Sen2Cor、MAJA和Fmask，在有效区分云和高亮地表以及识别薄卷云和云阴影方面表现出不同的局限性。这些局限性强调了继续改进云检测技术以提升LULC制图能力的必要性。此外，揭示云和不同云掩膜对LULC制图准确性的定量影响也是另一个需要进一步探索的问题。另一方面，识别动态变化的LULC类别，特别是水域变化（如稻田），具有挑战性但对准确的年度LULC制图非常重要。同时，在年度LULC制图中，综合利用一年内所有可用的时间序列影像，有望进一步提升制图精度。</p> <p>为提高多云和多雨地区的高时间密度LULC制图，本研究提出了一种集成的时间序列LULC制图方法，以改进在密集云覆盖和变化的水域条件下的LULC制图。该方法旨在生成和合成高精度空间无缝的近实时、月度、季度和年度LULC产品。具体地，构建了分别用于云与云阴影检测和LULC分类的融合任务特定光谱指数的深度模型。通过基于时间序列优化的云掩膜精细化，将有望减少云覆盖对LULC制图的影响。同时，时间序列影像中云覆盖区域的重建将有助于提高LULC制图的准确性。特别是后分类处理过程中考虑的时间变化模式有助于识别如农作物等可能频繁发生在水陆交互中的类别。本研究的目标包括：1）开发一种在多雨和多云地区进行高质量时间序列LULC制图的综合方法；2）揭示云对LULC制图的影响以及时间序列重建和使用密集影像时间序列进行LULC制图的益处；3）在研究区域生产一系列优于其它现有产品的LULC产品。该方法有望应用于世界其它地区，特别是在多云地区生成高度可靠的LULC产品。</p> <h4 id="2-研究区域和数据"><strong>2.</strong> <strong>研究区域和数据</strong></h4> <p>广东-香港-澳门大湾区（以下简称大湾区）（图1），包含珠江三角洲地区在内的11个主要城市，作为中国最发达的地区之一，在近几十年经历了快速的土地利用和土地覆盖变化。大湾区的多云和多雨天气条件对高时间密度的LULC制图构成了挑战，特别是在每年的雨季，该地区会出现密集的云层覆盖。珠江和沿海环境的存在导致了大湾区中土地和水体相互作用频繁，从而引起LULC类型的高度动态变化。因此，本研究选择大湾区作为研究区域，以检验所提出的方法在多云地区进行LULC制图的有效性。</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 1.png" alt="" width="650"/></div> <p>图1. 研究区域珠江三角洲及该区域Sentinel-2影像月平均云覆盖百分比。上图：研究区域的位置和验证样本点的分布；下图：2019至2022年间研究区域内Sentinel-2影像的平均每月云覆盖百分比。</p> <p>本研究通过GEE平台导出了从2018年12月1日到2023年1月31日跨越4年的大湾区Sentinel-2地表反射率时间序列影像数据集。所有导出的Sentinel-2影像光谱波段的空间分辨率统一重采样为10米，时间分辨率因不同区域而异为2至5天。典型地，Sentinel-2A/B卫星影像每5天覆盖一次大湾区的大部分地区，研究期间总共获得了299次覆盖。在这4年间，大湾区的Sentinel-2时间序列影像中云覆盖密集，估计的平均云覆盖率高达51.61%（基于本研究方法生成云掩膜统计，未包含薄云和云阴影）。图1中提供了每年的月平均云覆盖百分比，这表明由于密集云覆盖，在大湾区进行高质量和高时间密度的LULC制图具有挑战性。为了高效处理密集时间序列影像数据，如图1所示，大湾区的Sentinel-2时间序列被划分为40 × 30部分重叠的影像瓦片进行逐块数据获取和处理，实验仅涉及覆盖大湾区范围的695个瓦片。此外，本研究通过人工解译Google Earth中的高分辨率卫星影像收集样本点，以全面评估时间序列LULC产品。如图1所示，通过分层随机抽样选择了大湾区的1263个样本点，覆盖了2018年12月至2023年1月之间的多个日期，以考虑LULC变化区域。因此，在上述期间内发生LULC变化的样本点将与多个日期和LULC类别关联，而在整个研究期间内同一LULC类别的样本点仅与单一LULC类别关联，以用于对时间序列LULC产品进行更全面的综合评估。</p> <h4 id="3-研究方法"><strong>3.</strong> <strong>研究方法</strong></h4> <p>本研究提出了一种集成的多云地区高时间密度LULC制图方法，该方法包含四个主要步骤（图2）。首先，所提出的方法通过基于光谱指数融合深度学习模型生成时间序列Sentinel-2影像的初始云与云阴影掩膜。然后，通过时间序列滤波重建Sentinel-2时间序列影像中被云或云阴影覆盖的像元，在此过程中，初始的云与云阴影掩膜被迭代优化和更新以改善重建效果。接着，将重建后的时间序列影像输入到另一个全球样本库训练的深度模型中进行LULC分类。最后，进行分类后处理，包括时空众数滤波和考虑水陆交互的时间序列优化，以提高LULC制图的准确性和一致性。通过定量评价和与现有LULC产品在大湾区范围进行比较，评估所生成的LULC产品的精度，以及云覆盖对LULC制图的影响。</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 2.png" alt="" width="600"/></div> <center>图2. 本研究所提出的时间序列LULC制图方法流程图</center> <h4 id="4-结果与分析"><strong>4.</strong> <strong>结果与分析</strong></h4> <p>使用覆盖大湾区的4年Sentinel-2时间序列影像作为实验数据，总共存在695块时间序列影像瓦片。所有时间序列影像瓦片都根据图1所示的流程逐块处理，使用预训练的云与云阴影检测模型和LULC分类模型。对于所构建的融合光谱指数的深度学习模型，本研究在云与云阴影检测以及LULC分类两个任务上分别进行了精度验证，均在所对比的方法模型中取得了最佳表现。通过合成和拼接时间序列LULC分类图瓦片，最终可以生成整个大湾区的月度、季度和年度LULC分类图。本研究将生成的大湾区LULC产品命名为GBACover，通过使用人工标记的LULC样本对其进行定量精度评估，并将其与其它全球LULC产品在大湾区进行比较，全球LULC产品在大湾区进行比较，包括ESA WorldCover、Esri Land Cover和Google Dynamic World。所有三个现有的LULC产品均是基于机器学习方法生成，使其与所提出方法生成的LULC产品具有可比性。</p> <p>考虑到四个比较产品之间的差异，本研究将LULC产品类别颜色方案统一为ESA WorldCover产品的相同方案，LULC类型的命名按照Dynamic World训练数据集中的定义进行统一。评估结果表明，在2019年至2022年连续四年中，GBACover在大湾区年度LULC制图中的总体精度最高。与此同时，Google Dynamic World和Esri Land Cover在个别年份的表现较好。评估显示，GBACover在2019-2022年大湾区年度制图中的平均总体精度为87.01%，优于ESA WorldCover的83.98%（仅2020和2021年平均）、Esri Land Cover的85.26%和Google Dynamic World的85.06%。如果在精度评估中排除ESA WorldCover中的湿地类别，因缺少其验证样本，那么2020年和2021年ESA WorldCover的平均总体精度为85.82%，这高于其实际精度，因为湿地类别的准确识别具有挑战性。值得注意的是，不同时间段合成的LULC产品精度存在时间差异。尽管GBACover在年度尺度上实现了87.01%的平均总体精度，但所提出方法生成的时间序列LULC产品在近实时尺度上的平均总体精度为80.13%。图3展示了2019年至2022年连续4年中大湾区珠江河口地区的年度LULC分类图，其展示了GBACover相对于其它LULC产品在陆地与水体类别转换发生频繁地区（如稻田）的显著差异。</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 3.png" alt="" width="900"/></div> <center>图3. 2019-2022年珠江口区域LULC分类图比较</center> <p>本研究还评估了使用不同云掩膜对生成的时间序列LULC分类结果精度的影响。具体地，使用QA60、Sen2Cor、s2cloudless以及所提出的SIFDM模型在时间序列优化前后的掩膜进行比较，以定量评估云和云阴影掩膜精度对LULC制图的影响。具体来说，基于未重建的原始Sentinel-2时间序列影像生成的时间序列LULC分类图，使用大湾区中的人工标记样本进行验证。在验证之前，从生成的时间序列LULC分类图中排除由所比较的掩膜标记的云或云阴影像元，这将使得评估使用不同掩膜进行LULC制图表现成为可能。评估结果表明，利用本研究提出的SIFDM模型生成的优化和初始云掩膜，相较于其它比较的掩膜，在云和云阴影掩膜中表现最佳，分别在时间序列LULC制图中实现了81.16%和68.06%的最佳总体精度。优化后掩膜甚至可以比SIFDM生成的原始掩膜贡献更高的总体LULC分类精度，确认了时间序列优化在提高云掩膜精度方面的益处。更精确的云掩膜有助于提高LULC制图的精度。使用s2cloudless生成的两组掩膜，在灰度掩膜分割的二值化阈值分别为25和50时，分别导致了59.35%和57.04%的总体LULC分类精度。使用Sen2Cor掩膜进行LULC分类的总体精度为64.21%，高于s2cloudless，可能是由于Sen2Cor掩膜中标注了额外的云阴影信息。QA60生成的较不精确的云掩膜导致了47.99%的总体LULC分类精度，用户在应用QA60掩膜进行Sentinel-2影像解译时应注意这一点。此外，值得注意的是，在基于深度学习的卫星影像解译相关研究中，很少考虑云掩膜的精度。这一疏忽引起了对在多云条件下使用光学卫星影像进行陆地和水体动态精确制图的关注。本研究不仅通过结合先进的云掩膜和LULC分类模型提供了一种在多云地区进行LULC制图的综合方法，还评估了云掩膜对LULC制图的影响。评估结果表明，应用不同云掩膜进行LULC制图的精度差异显著，从47.99%到81.16%不等，强调了精确的云掩膜对时间序列LULC制图的重要性。</p> <h4 id="5-讨论"><strong>5.</strong> <strong>讨论</strong></h4> <h5 id="51-时间序列重建对lulc制图的益处"><strong>5.1 时间序列重建对LULC制图的益处</strong></h5> <p>本研究应用Whittaker滤波对影像时间序列中受云与云阴影影响的像元进行重建，以提升多云地区的LULC制图结果。在图4中，以农业用地的LULC制图为例，农业用地可能被水覆盖或种植作物，并且在一年内水和作物之间的土地覆盖类别变化可能会发生多次。在这种情况下，LULC类型（如作物和湿地）的制图结果会随所涉及的影像而变化，导致涉及土地和水体相互作用的LULC类型的分类偏差。由于云覆盖在影像时间序列中随机发生，准确识别涉及土地和水体相互作用的LULC类别变得更加困难。对影像时间序列中受云或云阴影影响的区域进行重建对于准确的LULC制图是必要的，以最小化由随机云覆盖和选取固定时间范围影像引起的时间序列制图中的偏差和错误。基于重建后的无云时间序列影像，可以生成高质量的年度、季度甚至月度的LULC分类图。此外，可以考虑时间序列变化模式来优化制图结果。</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 4.png" alt="" width="900"/></div> <p>图4. 使用原始和重建的无云影像进行时间序列制图的比较。上图：使用原始影像生成的结果，其中时间序列中的缺失点由云覆盖引起。中图：使用重建影像和分类后处理后的时间序列制图结果。下图：基于原始和重建的无云影像获得的NDVI和NDWI时间序列。</p> <h5 id="52-使用密集时间序列影像进行年度lulc制图"><strong>5.2 使用密集时间序列影像进行年度LULC制图</strong></h5> <p>现有的年度LULC产品通常基于植被生长期获取的影像生成。然而，光学卫星影像在这些多雨和多云季节遭受密集云层覆盖，导致用于年度LULC制图的无云影像较为有限。因此，年度制图结果仅基于一张或几张有效的卫星观测影像生成。在本研究中，年度LULC分类图基于全年所有可用的Sentinel-2影像生成和合成。此外，进行时间序列LULC分类图的分类后处理，以提高时间序列的一致性并滤除噪声。因此，年度LULC制图的准确性和鲁棒性可以得到提高。使用密集影像时间序列进行LULC制图有望捕捉到周期性的LULC变化模式（例如作物区的土地和水体相互作用），这些模式可以通过时间序列的分类后处理和分析来识别。在图5中，可以从密集时间序列LULC分类图中获取LULC类型的频次，从中可以以高精度和直观的方式定量测量年度LULC变化趋势（例如，四年间从作物到建筑区的变化趋势）。因此，密集时间序列的分类后处理和分析有助于提升LULC制图的准确性和鲁棒性。</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 5.png" alt="" width="900"/></div> <p>图5. 从年度LULC频次图中识别变化趋势的示例。在此示例中，可以从其相应的年度LULC频次图清晰地解译从作物到建筑区的过渡，这些频次图是基于密集时间序列LULC分类图生成的，并表示在一年内检测到某一类别的次数与观测总次数的比例。</p> <h5 id="53-局限性"><strong>5.3 局限性</strong></h5> <p>尽管所提出的时间序列LULC制图方法在云掩膜和LULC分类方面优于比较方法，但所提出方法仍存在局限性。一方面，深度模型的性能受限于本研究中使用的训练样本的数量和质量，特别是用于训练LULC分类模型的Dynamic World训练数据集，该数据集粗糙且缺乏对象边界细节，从而限制了模型在识别桥梁和道路等小尺寸细物体方面的表现，仍有通过高质量训练标签进行进一步改进的空间。同时，通过使用最新的深度模型结构（如基于视觉Transformer的基础大模型，可以进一步提高深度模型的性能，这些模型已被证明在影像解译中有效，可以挖掘所提出方法的潜力。另一方面，由于所提出的制图方法涉及多个步骤，尤其是云与云阴影检测、时间序列重建和LULC分类，可能会发生累积的处理错误。此外，由于云的遮挡，短期的LULC变化可能无法有效重建和捕捉，或者可能在分类后处理过程中被平滑，这将导致近实时和每月尺度的LULC制图精度下降。</p> <h4 id="6-结论"><strong>6. 结论</strong></h4> <p>本研究提出了一种使用密集Sentinel-2时间序影像列进行LULC制图的综合方法。尽管在不同时间尺度上的分类精度上存在差异，该方法可以用于多云地区的近实时、月度、季度和年度制图。通过开发深度模型以提高云掩膜和LULC分类的准确性、采用时间序列重建方法填补云覆盖区域、并应用时间序列分类后处理和分析，提出的方法在云掩膜和LULC分类方面展示出了优越性。在粤港澳大湾区的应用表明，该方法可以生成准确的LULC分类图，在年度尺度上的平均总体精度为87.01%，在近实时尺度上的精度为80.13%，优于比较的年度LULC产品。本研究评估了云覆盖对LULC制图的影响，提出了开发先进云与云阴影检测方法以提高LULC制图精度的必要性，这在本研究中已得到验证。本文还讨论了时间序列重建和使用密集时间序列影像进行LULC制图的益处，展示了它们对LULC制图的贡献，特别是在改善涉及陆地和水体交互的LULC类型以及多云地区的制图结果方面。</p> <p>所提出方法中的深度模型是在全球收集的数据集上训练的，因而可以用于研究区域以外的其它地区的LULC制图。同时，所提出的方法还可以用于单一LULC类别的近实时监测（例如农田、湿地和淹没土地的时间序列监测），因此具有广泛的潜在应用。然而，所提出的方法在深度模型性能和多重处理步骤带来的误差传播方面的局限性留有很多改进空间，例如与最新的基础大模型集成以及在LULC分类图生产过程中引入质量控制。此外，研究区的实地调查是进一步验证LULC产品所必需的，特别是在具有挑战性的制图场景中，例如草地/灌木、湿地和淹没植被类别。未来，随着更先进的深度模型（例如基础大模型）的引入和多模态数据（例如Sentinel-1和Sentinel-1的结合）的应用，多云和多雨地区的密集影像时间序列LULC制图可以得到进一步增强。SAR影像的潜力可以得到充分利用，以有利于在持续云覆盖期间识别土地动态变化。</p> <h4 id="主要作者简介"><strong>主要作者简介：</strong></h4> <p><strong>李志伟</strong>，博士，香港理工大学土地测量及地理资讯学系研究助理教授。主要研究兴趣为多云多雨环境遥感，研究方向包括卫星影像云检测与去除，多源数据融合，土地覆盖制图，洪水监测等。个人主页：https://zhiweili.net/。</p> <p><strong>翁齐浩</strong>，欧洲科学院外籍院士、 美国科学促进会（AAAS）‍会士、电气与电子工程师协会（IEEE）会士、美国地理学会（AAG）会士、美国摄影测量与遥感学会（ASPRS）会士、亚太人工智能学会（AAIA）会士，现任香港理工大学地理信息学和人工智能讲座教授、曾任美国印第安纳州立大学城市与环境变化中心主任和教授和美国航天局高级研究员。现为地球观测组织的全球城市观测和信息系统项目负责人并任《国际摄影测量与遥感学会期刊》（ISPRS J P&amp;RS）主编。翁教授的研究侧重于遥感科学和技术在城市环境与生态系统中的应用、土地利用和土地覆盖的变化和城市化的环境效应等。</p> <p>论文已支持Open Access，点击<a href="https://doi.org/10.1016/j.rse.2024.114190">阅读原文</a>即可获取全文。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Li Z. et al., 2024, Remote Sens. Environ.]]></summary></entry><entry><title type="html">Time-series land use and land cover mapping in cloud-prone areas</title><link href="https://zhiweili.net//blog/2024/lulc-mapping/" rel="alternate" type="text/html" title="Time-series land use and land cover mapping in cloud-prone areas"/><published>2024-06-05T00:00:00+00:00</published><updated>2024-06-05T00:00:00+00:00</updated><id>https://zhiweili.net//blog/2024/lulc-mapping</id><content type="html" xml:base="https://zhiweili.net//blog/2024/lulc-mapping/"><![CDATA[<p>Li, Z., Weng, Q., Zhou, Y., Dou, P., &amp; Ding, X. (2024). Learning spectral-indices-fused deep models for time-series land use and land cover mapping in cloud-prone areas: The case of Pearl River Delta. <em>Remote Sensing of Environment</em>, 308, 114190. [<a href="https://doi.org/10.1016/j.rse.2024.114190">HTML</a>] <a href="https://zhiweili.net/assets/pdf/2024.7_RSE_Learning%20spectral-indices-fused%20deep%20models%20for%20time-series%20land%20use%20and%20land%20cover%20mapping%20in%20cloud-prone%20areas.pdf">[PDF]</a></p> <h4 id="highlights"><strong>Highlights</strong></h4> <ul> <li>Novel LULC mapping via indices-fused deep models and time series reconstruction.</li> <li>High-temporal-density 10 m seamless LULC mapping in cloudy and rainy areas (PRD).</li> <li>Overall mapping accuracy yielded up to 87.01%, outperforming existing LULC products.</li> <li>Potential to generate seamless near real-time maps and high-quality LULC data sets.</li> </ul> <h4 id="abstract"><strong>Abstract</strong></h4> <p>Mapping of highly dynamic changes in land use and land cover (LULC) can be hindered by various cloudy conditions with optical satellite images. These conditions result in discontinuities in high-temporal-density LULC mapping. In this paper, we developed an integrated time series mapping method to enhance the LULC mapping accuracy and frequency in cloud-prone areas by incorporating spectral-indices-fused deep models and time series reconstruction techniques. The proposed method first reconstructed cloud-contaminated pixels through time series filtering, during which the cloud masks initialized by a deep model were refined and updated during the reconstruction process. Then, the reconstructed time series images were fed into a spectral-indices-fused deep model trained on samples collected worldwide for classification. Finally, post-classification processing, including spatio-temporal majority filtering and time series refinement considering land–water interactions, was conducted to enhance the LULC mapping accuracy and consistency. We applied the proposed method to the cloud- and rain-prone Pearl River Delta (i.e., Guangdong–Hong Kong–Macao Greater Bay Area, GBA) and used time series Sentinel-2 images as the experimental data. The proposed method enabled seamless LULC mapping at a temporal frequency of 2–5 days, and the production of 10 m resolution annual LULC products in the GBA. The assessment yielded a mean overall accuracy of 87.01% for annual mapping in the four consecutive years of 2019–2022 and outperformed existing mainstream LULC products, including ESA WorldCover (83.98%), Esri Land Cover (85.26%), and Google Dynamic World (85.06%). Our assessment also reveals significant variations in LULC mapping accuracies with different cloud masks, thus underscoring their critical role in time series LULC mapping. The proposed method has the potential to generate seamless and near real-time maps for other regions in the world by using deep models trained on datasets collected globally. This method can provide high-quality LULC data sets at different time intervals for various land and water dynamics in cloud- and rain-prone regions. Notwithstanding the difficulties of obtaining high-quality LULC maps in cloud-prone areas, this paper provides a novel approach for the mapping of LULC dynamics and the provision of reliable annual LULC products.</p> <h4 id="1-introduction"><strong>1.</strong> <strong>Introduction</strong></h4> <p>Land use and land cover (LULC) datasets play a vital role as fundamental data in various applications, including land use planning and management, eco-environment conservation, and agriculture. LULC mapping has consistently been a popular research topic, and it continues to evolve alongside the advancements in data acquisition and processing capacities. Over the past few decades, the spatial resolution of LULC mapping has been continuously improved from medium to high resolution at the meter- and even submeter-levels. Meanwhile, the temporal frequency of LULC mapping is also promoted from annual mapping to near real-time mapping. Recent machine learning techniques, especially deep learning, have significantly revolutionized LULC mapping, and are widely used for producing new regional and global LULC products. The advancements of LULC mapping in the above-mentioned aspects have marked a significant milestone in achieving accurate and continuous LULC mapping with dense image time series. Despite the remarkable progress made in recent years, two major issues in the field of LULC mapping persist. On one hand, the cloud coverage in optical image time series reduces the availability of data for time series LULC mapping. Meanwhile, the importance of accurate cloud masks cannot be overstated for precise high-temporal-density near real-time LULC mapping, especially in cloud-prone areas. However, the cloud masks that are commonly used are often not highly accurate, as evidenced by multiple recent studies, leaving space for further improvements. Specifically, for Sentinel-2 imagery, the Sentinel-2 Level 1-C cloud mask product has been found to generally underestimate cloud presence, which cannot be ignored. Other existing cloud detection methods, such as Sen2Cor, MAJA, and Fmask, exhibit varying limitations in accurately distinguishing clouds from bright ground surfaces and in effectively identifying thin cirrus clouds and cloud shadows, as summarized in the recent study. These limitations highlight the necessity for more sophisticated methods, such as the deep learning model, which offers improved accuracy through the use of multiscale features but is limited by the requirement for extensive training data. Despite the progress made, the accuracy of cloud masks remains suboptimal, underscoring the necessity for ongoing efforts to refine cloud detection techniques to enhance LULC mapping capabilities. Additionally, revealing the quantitative effects of clouds and different cloud masks on the accuracy of LULC mapping is another aspect that warrants further exploration. On the other hand, the identification of dynamically changing land patterns, especially over varying water areas, such as paddy fields, is challenging but important for the composition of accurate annual LULC maps. Meanwhile, the annual LULC mapping, which leverages all available image time series within a year, is expected to further promote the mapping accuracy. To improve high-temporal-density LULC mapping in cloudy and rainy areas, we proposed an integrated time series LULC mapping method to enhance the LULC mapping under dense cloud coverage and varying water conditions. This method aims to generate and composite seamless near real-time, monthly, seasonal, and annual LULC maps with high accuracy. Specifically, spectral-indices-fused deep models that fuse task-specific spectral indices from images are constructed for cloud masking and LULC classification, respectively. The refined cloud masks through time series refinement are expected to reduce the negative influences of clouds on LULC mapping. Meanwhile, the reconstruction of time series cloudy images will benefit LULC mapping in terms of accuracy. In particular, the consideration of temporal change patterns in post-classification processing benefits the identification of classes, such as crops, which may frequently occur in water–land interactions. The objectives of this study are as follows: 1) develop an integrated method for high-quality time series LULC mapping in rainy and cloudy areas; 2) reveal the effects of clouds on LULC mapping and the benefits of time series reconstruction and LULC mapping with dense image time series; and 3) produce a series of LULC products over the study area that outperform the other existing products. The proposed method is expected to be applied in other regions in the world to generate highly reliable LULC products, especially in cloud-prone areas.</p> <h4 id="2-study-area-and-data"><strong>2.</strong> <strong>Study area and data</strong></h4> <p>The Guangdong–Hong Kong–Macao Greater Bay Area (GBA thereafter) (Fig. 1), one of the most developed regions in China, encompasses a total of 11 major cities and spans in the Pearl River Delta region, which has experienced rapid land use and land cover changes in the recent decades. The rainy and cloudy weather conditions in the GBA present a challenge for high-temporal-density LULC mapping, especially during annual rainy seasons when the region experiences dense cloud coverage. The existence of the Pearl River and coastal environment results in frequent land and water interactions in the GBA, leading to highly dynamic changes in LULC types in the region. Thus, GBA is selected as the study area to examine the effectiveness of the proposed method for LULC mapping in cloud-prone areas.</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 1.png" alt="" width="650"/></div> <p>Fig. 1. Study area Pearl River Delta and monthly cloud percentage in Sentinel-2 imagery utilized for the study. The upper image shows the location of the study area and the distribution of validation sample sites. The lower image represents the average monthly percentages of cloud coverage in Sentinel-2 imagery in the study area during 2019–2022.</p> <p>The harmonized Sentinel-2 Level-2A (i.e., surface reflectance) image time series in the GBA is exported through the Google Earth Engine (GEE) platform. In addition, the LULC mapping experiments incorporated an image dataset spanning 4 years from December 1, 2018, to January 31, 2023. Majority of the areas in the GBA are revisited by Sentinel-2A/B satellites every 5 days, resulting in a total of 299 typical coverages during the study period. The Sentinel-2 time series over GBA among the 4 years are densely covered by clouds with an estimated mean cloud percentage as high as 51.61%. The monthly mean cloud percentages for each year are provided in Fig. 1, which depicts that high-quality and high-temporal-density LULC mapping in GBA is challenging due to the cloud coverage. To efficiently proceed with dense time series image data, as shown in Fig. 1, the Sentinel-2 time series in the GBA is divided into 40×30 image tiles for tile-by-tile data acquisition and processing. Only the 695 tiles that cover the GBA are involved for experiments. In addition, we collected sample points based on very high-resolution satellite images in Google Earth through manual interpretation to comprehensively evaluate the time series LULC products. In Fig. 1, the 1263 sample sites over GBA are selected by stratified random sampling. The selected sample points cover multiple dates between December 2018 and January 2023, with consideration for the LULC-changed areas. Accordingly, multiple labels are associated with different dates for sample points where LULC changes occurred during the above-mentioned period. Meanwhile, only a single label is associated without a specific date for sample points that belong to the same LULC category over the entire study period, if all manually interpreted labels are in the same category based on all available historical observations on Google Earth during the study period. Such a collection of sample points, including the LULC-changed and unchanged areas over time, will guarantee a more comprehensive evaluation of time series LULC products.</p> <h4 id="3-methodology"><strong>3.</strong> <strong>Methodology</strong></h4> <p>We proposed an integrated LULC mapping method, which comprises four main steps (Fig. 2). The proposed method first initializes cloud and cloud shadow masks for time series Sentinel-2 images by the spectral-indices-fused deep model based on CNN. The cloud- or cloud shadow-contaminated pixels in the Sentinel-2 time series are then reconstructed through time series filtering, during which the initial cloud masks are refined to improve the reconstruction effects. Thereafter, the reconstructed time series images are fed into another deep model trained on samples collected worldwide for LULC classification. Finally, post-classification processing is conducted to enhance the LULC mapping accuracy and consistency. The accuracy of the produced LULC products is quantitatively evaluated and compared with existing mainstream LULC products in the GBA. In particular, the effects of the cloud coverage on LULC mapping are evaluated.</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 2.png" alt="" width="600"/></div> <center>Fig. 2. The flowchart of the proposed time series LULC mapping method.</center> <h4 id="4-results-and-analysis"><strong>4.</strong> <strong>Results and analysis</strong></h4> <p>The 4-year Sentinel-2 time series covering GBA was used as the experiment data, in which a total of 695 tiles of image time series exist. All image time series tiles are processed tile by tile according to the processes shown in Fig. 1 by using the pretrained cloud masking model and LULC classification model. The spectral-indices-fused deep learning models were separately validated for both cloud and cloud shadow detection and LULC classification tasks, and they achieved the best performance among the compared methods. The monthly, seasonal, and annual LULC maps for the entire GBA can be finally produced by composting and mosaicking time-series LULC map tiles. We named the generated LULC products in GBA as GBACover, which include a series of dense time series LULC maps at multiple temporal densities (i.e., near real-time, monthly, seasonal, and annual scales). The accuracy of the generated GBACover products can be quantitatively evaluated and compared with other global LULC products over the GBA, including ESA WorldCover, Esri Land Cover, and Google Dynamic World by using the manually interpreted LULC samples in GBA. All three existing LULC products were produced based on machine learning methods, making them highly accurate and comparable with LULC maps generated with the proposed method.</p> <p>Considering the differences among the four compared products, the coloring scheme for mapping is unified to the same scheme as ESA WorldCover products. The naming of LULC types is also unified as defined in the Dynamic World training dataset. Table 3 shows the accuracy of our annual GBACover products and the other compared LULC products over the GBA from 2019 to 2022. The validation results suggested that GBACover has the highest overall accuracy for the annual LULC mapping in GBA over the four consecutive years of 2019–2022. Meanwhile, Google Dynamic World and Esri Land Cover are the second best for their better performances in separate years. The assessment shows a mean overall accuracy of 87.01% of GBACover for annual mapping in 2019–2022 over GBA and outperforms ESA WorldCover of 83.98% in 2020 and 2021, Esri Land Cover of 85.26%, and Google Dynamic World of 85.06%. If the accuracy assessment for wetlands in ESA WorldCover are excluded due to the absence of validation labels, the mean overall accuracy of ESA WorldCover 2020 and 2021 is 85.82%, which is higher than its actual accuracy because of challenges in the accurate identification of wetlands. It is worth noting that there is temporal variance in the classification accuracy of composited LULC maps across different lengths of periods. Despite the GBACover achieving a mean overall accuracy of 87.01% at an annual scale, the validation of the time series LULC maps generated by the proposed method reports a mean overall accuracy of 80.13% at a near real-time scale. The annual LULC maps over the Pearl River estuary region in the consecutive 4 years from 2019 to 2022 are shown in Fig. 3, which confirms the superiority of GBACover compared with other LUCL products, especially over varying water areas, such as paddy fields.</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 3.png" alt="" width="900"/></div> <center>Fig. 3. Comparison of LULC mapping in the Pearl River estuary region in 2019–2022. </center> <p>This study also evaluated the impact of using different cloud masks on the accuracy of the generated time series LULC classification results. The masks from QA60, Sen2Cor, s2cloudless, and masks generated by the proposed SIFDM model before and after time series refinement are involved in the comparisons to quantitatively evaluate the influence of the accuracy of cloud and cloud shadow masks on LULC mapping. Specifically, the time series LULC maps, generated based on the original Sentinel-2 time series without reconstruction, are validated with the manually labeled samples in GBA. The cloud/cloud shadow contaminated pixels, identified by the compared masks, are excluded from the generated time series LULC maps before validation. This process allows for the evaluation of LULC mapping performances with different masks. Specifically, the utilization of the refined and initial cloud masks generated by SIFDM, which perform best in cloud and cloud shadow masking compared with other compared masks, results in the best overall accuracies of 81.16% and 68.06% for the time series LULC mapping, respectively. The refined masks can even contribute to a higher overall LULC classification accuracy than the original masks generated by SIFDM, confirming the benefits of time series refinement for improving the accuracy of cloud masks. More accurate cloud masks contribute to the higher accuracy of LULC mapping. The two collections of masks generated by s2cloudless result in the overall LULC classification accuracy of 59.35% and 57.04% with two different binarization thresholds of 25 and 50 for the grayscale mask segmentation, respectively. The overall accuracy of the LULC classification with Sen2Cor masks is 64.21%, which is higher than that of s2cloudless, potentially due to the additional cloud shadow information labeled in Sen2Cor masks. The less accurate cloud masks from QA60 result in an overall LULC classification accuracy of 47.99%, which is worth the users’ attention for the application of QA60 masks for Sentinel-2 image interpretation. However, it is noteworthy that the accuracy of cloud masks is rarely considered in studies relevant to satellite image interpretation based on deep learning. This oversight raises concerns regarding the accurate mapping of land and water dynamics with optical satellite images, especially in cloudy conditions. This paper not only provides a comprehensive methodology for LULC mapping in cloud-prone areas by incorporating advanced cloud masking and LULC classification models but also assesses the influences of cloud masks on LULC mapping. The assessment reveals that LULC mapping accuracies vary significantly, from 47.99% to 81.16%, when applying different cloud masks, thus underscoring the importance of accurate cloud masks for time series LULC mapping.</p> <h4 id="5-discussion"><strong>5.</strong> <strong>Discussion</strong></h4> <h5 id="51-benefits-of-time-series-reconstruction-for-lulc-mapping"><strong>5.1 Benefits of time series reconstruction for LULC mapping</strong></h5> <p>This study applied Whittaker filtering for the time series reconstruction of the contaminated pixels in the image time series, which is expected to benefit dealing with LULC mapping in cloud-prone areas. In Fig. 4, taking LULC mapping in agriculture land as an example, an agriculture land can either be covered by water or planted with crops, and the land cover change between water and crops may occur several times within a year. In this case, the mapping results vary with the involved images for LULC mapping, resulting in biases for mapping of LULC types that involve land and water interactions (e.g., crops and wetland). The accurate mapping of the LULC types that involve land and water interactions becomes more challenging because the cloud coverage on the image time series randomly occurs. Reconstruction of the cloud- or cloud shadow-contaminated areas in the image time series is necessary for the accurate LULC mapping to minimize the biases and errors in time series mapping caused by the random cloud coverage and selected images. Composting high-quality annual, seasonal, and even monthly LUCL maps is possible because of the reconstructed cloud-free image time series. The time series change patterns can be considered to refine the mapping results.</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 4.png" alt="" width="900"/></div> <p>Fig. 4. Comparisons of time series mapping with the original and the reconstructed cloud-free images. The upper figure denotes the results generated with the original images, in which the missing points in the time series are caused by cloud coverage. The middle figure refers to the time series mapping results with the reconstructed images and after post-classification processing. The lower figure provides the NDVI and NDWI time series derived from both the original and the reconstructed cloud-free images, respectively.</p> <h5 id="52-annual-lulc-mapping-with-dense-image-time-series"><strong>5.2 Annual LULC mapping with dense image time series</strong></h5> <p>Existing annual LULC products are typically produced based on images acquired during the vegetation growing season. However, optical satellite imagery suffers from dense cloud coverage during these rainy and cloudy seasons, resulting in limited available cloud-free images for the annual LULC mapping. Accordingly, the annual mapping results are generated only based on one or several valid satellite observations. In this study, the annual LULC maps are generated and composited based on all available Sentinel-2 images for a year. Post-classification processing for the time series LULC maps is additionally conducted to improve the time series consistency and filter out noises. Consequently, the accuracy and robustness of the annual LULC mapping can be improved and enhanced. LULC mapping with dense image time series holds promise in capturing the periodic LULC change patterns (e.g., the land and water interactions in crop areas), which can be identified through the time series post-classification processing and analysis. In Fig. 5, the frequencies of the LULC types can be acquired from dense time series LULC maps, from which the annual LULC change trends can be quantitatively measured with high accuracy and in an intuitive manner (e.g., the change trends from crops to built area over the 4 years). Therefore, dense time series post-classification processing and analysis benefit LULC mapping in terms of accuracy and robustness.</p> <div align="center"><img src="/assets/img/blogs/2024_lulc mapping/Fig. 5.png" alt="" width="900"/></div> <p>Fig. 5. Example of identifying change trends from the annual LULC frequency maps. The transition from crops to built area in this example can be clearly interpreted from their corresponding annual LULC frequency maps, which are generated based on dense time series LULC maps and represent the proportion of times a category is detected out of the total number of observations in a year.</p> <h5 id="53-limitations"><strong>5.3 Limitations</strong></h5> <p>Although the proposed time series LULC mapping method achieved better performances than the compared methods in terms of cloud masking and LULC classification, the limitations still exist with the proposed method. On the one hand, the performance of deep models is subjective to the amount and quality of training samples used in this study, especially the Dynamic World training dataset for the training of the LULC classification model, which is rough and lacks details in object boundaries, thus limiting the model performance in identifying slim ground objects with minor sizes, such as bridges and roads, and leaving space for further improvements with high-quality training labels. Meanwhile, the performance of deep models can be further enhanced by using state-of-the-art deep architectures, such as vision transformer based foundation models, which have been proven effective in image interpretation, to exploit the potentials of the proposed method. On the other hand, cumulated processing errors can occur because multiple steps are involved in the LULC method, especially the accuracy of masks, time series reconstruction, and LULC classification. Additionally, short-term LULC changes might be hidden by clouds and cannot be effectively reconstructed and captured or might be smoothened in post-classification processing, which will result in a decrease in accuracy for near real-time and monthly LULC mapping.</p> <h4 id="6-conclusions"><strong>6. Conclusions</strong></h4> <p>An integrated method for LULC mapping using dense Sentinel-2 time series is proposed in this paper. This method can be used for near real-time, monthly, seasonal, and annual mapping in cloud-prone areas, despite the temporal variance in classification accuracy across different lengths of periods. The proposed methods have shown their superiority over the compared methods in cloud masking and LULC classification by developing deep models for improving the accuracy of cloud masking and LULC classification, employing a time series reconstruction method for filling cloud-contaminated pixels, and applying time series post-classification processing and analysis. The application of the proposed method in the GBA suggested that it can generate accurate LULC maps, achieving a mean overall of 87.01% at an annual scale and 80.13% at a near real-time scale, thereby outperforming the compared annual LULC products. We evaluated the influence of cloud coverage on LULC mapping, suggesting the necessity of developing advanced cloud masking methods to improve LULC mapping accuracy, as has been done in this study. The benefits of time series reconstruction and LULC mapping with dense time series images were also discussed, which illustrate their contributions to LULC mapping, especially in improving mapping results for LULC types involved in land and water interactions and in cloud-prone areas. The deep models in the proposed method are trained on datasets collected globally, which can be used for LULC mapping in other regions worldwide beyond the study area. Meanwhile, the proposed method can also be applied for near real-time monitoring of a single LULC category (e.g., time series monitoring of cropland, wetland, and inundated land), thus having a broad range of potential applications. Nevertheless, the limitations of the proposed method in the performance of deep models and error propagation brought by multiple processing steps leave much space for further improvements, such as integrating with the state-of-the-art large foundation model and introducing quality control during the production of LULC maps. Additionally, field surveys in the study area are required to further validate the LULC products, especially in challenging mapping scenarios, such as for grass/shrub, wetland, and flood vegetation classes. In the future, with the introduction of more advanced deep models (e.g., large foundation models) and multi-modal data (e.g., combination of Sentinel 1 and 2), the LULC mapping with dense image time series in cloud- and rain-prone areas can be further enhanced. The potentials of SAR images can be fully exploited to benefit the identification of dynamic land change patterns during periods of persistent cloud coverages.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Li Z. et al., 2024, Remote Sens. Environ.]]></summary></entry><entry><title type="html">光学卫星影像云与云阴影检测：特征、算法、验证和前景 [in Chinese]</title><link href="https://zhiweili.net//blog/2022/cloud-detection-review-CHN/" rel="alternate" type="text/html" title="光学卫星影像云与云阴影检测：特征、算法、验证和前景 [in Chinese]"/><published>2022-07-05T00:00:00+00:00</published><updated>2022-07-05T00:00:00+00:00</updated><id>https://zhiweili.net//blog/2022/cloud-detection-review-CHN</id><content type="html" xml:base="https://zhiweili.net//blog/2022/cloud-detection-review-CHN/"><![CDATA[<p>Li, Z., Shen, H., Weng, Q., Zhang, Y., Dou, P., Zhang, L. (2022). Cloud and cloud shadow detection for optical satellite imagery: Features, algorithms, validation, and prospects. ISPRS Journal of Photogrammetry and Remote Sensing, 188, 89–108. [<a href="https://doi.org/10.1016/j.isprsjprs.2022.03.020">HTML</a>] <a href="https://zhiweili.net/assets/pdf/2022.6_ISPRS%20P&amp;RS_Cloud%20and%20cloud%20shadow%20detection%20for%20optical%20satellite%20imagery%EF%BC%9AFeatures,%20algorithms,%20validation,%20and%20prospects.pdf">[PDF]</a> <a href="https://github.com/dr-lizhiwei/OpenSICDR">[Project]</a></p> <h4 id="摘要"><strong>摘要</strong></h4> <p>云的存在阻碍了光学卫星成像系统获取有用的地面观测信息，并对光学卫星影像的处理和应用产生负面影响。因此，云及其伴随阴影的检测是光学卫星影像预处理的一个重要步骤。由于人们对时间序列影像分析和遥感数据挖掘的兴趣，近几十年来，这一领域已成为研究的热点。本综述首先分析了该领域的发展趋势，总结了云与云阴影检测方法在特征、算法、结果验证等方面的研究进展和成果，随后讨论了存在的问题，并在最后提出了未来的展望。本文旨在探索云与云阴影检测领域的新研究趋势和机会，同时为选择最合适的方法来解决光学卫星影像中的云覆盖问题提供参考，这对于多云和多雨地区的遥感至关重要。未来，我们可以预见到准确性和通用性的提升，物理模型与深度学习的结合，以及人工智能和在线大数据处理平台将能进一步提高处理效率并促进时间序列影像的应用。此外，本综述收集了最新的云与云阴影检测的开源工具和数据集，并发起了一个在线项目（Open Satellite Image Cloud Detection Resources，即OpenSICDR），以分享该领域最新的研究成果（<a href="https://github.com/dr-lizhiwei/OpenSICDR">https://github.com/dr-lizhiwei/OpenSICDR</a>）。</p> <h4 id="1-研究背景"><strong>1.</strong> <strong>研究背景</strong></h4> <p>在过去几十年里，随着大量光学卫星数据的发布和新数据源的不断引入，众多研究集中在对不同传感器拍摄的影像进行云与云阴影检测，并开发了众多方法。尽管以前的研究回顾了云与云阴影检测文献，但主要集中在方法的分类、云测量设备以及云与云阴影检测结果的形式。为了系统总结该领域目前的成就和挑战，本研究从特征、算法和验证的角度对云与云阴影检测文献进行了全面回顾，如图1所示。鉴于不同类别的算法可能通过使用相同类型的特征实现云与云阴影检测，且同一类别的算法也可能接受不同类型的特征，因此本综述从特征和算法两个角度分别回顾了不同的云与云阴影检测方法。本综述还总结了云与云阴影检测结果的主要类型及其验证。</p> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review//Fig. 1.png" alt="" width="1000"/></div> <center>图1. 云与云阴影检测：特征、算法和验证</center> <h4 id="2-文献分析"><strong>2.</strong> 文献分析</h4> <p>我们通过Scopus对光学卫星影像的云与云阴影检测主题进行了文献调查，搜索关键词包括<em>cloud/cloud shadow AND detection/masking/extraction/screening/identification</em>，搜索范围仅限于英文期刊论文的标题、关键词和摘要。根据截至2021年12月1日的搜索结果，在人工排除不相关的论文后，最终选择了504篇论文进行文献分析。注意到与云分类有关的论文，这些论文根据云相态和云高度将云进一步划分为不同的类型，没有包括在文献分析中进行讨论。此外，为了保证用于文献分析的论文的高质量，只选择了在正规期刊上发表的论文，并对每篇论文进行了人工检查和确认，以确保其符合本综述的主题。如图1所示，文献分析结果表明，从1985年到2021年的37年间，发表的论文数量及其引用率总体上呈上升趋势，尤其是最近十年，这表明该领域近期受到了广泛关注。图2-5还统计了该领域论文发表的主要国家/地区、机构和期刊。</p> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 2.png" alt="" width="600"/></div> <center>图2. 云与云阴影检测论文的发表数量及其引用次数（1985-2021年）</center> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 3.png" alt="" width="600"/></div> <center>图3. 该领域论文发表的主要国家/地区（发表了&gt;10篇期刊论文）</center> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 4.png" alt="" width="600"/></div> <center>图4. 该领域论文发表的全球主要研究机构（发表了&gt;10篇期刊论文）</center> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 5.png" alt="" width="600"/></div> <center>图5. 该领域论文发表的主要期刊（发表了&gt;10篇期刊论文）</center> <p>此外，本文统计了涉及不同类型卫星影像的论文数量，以确定这504篇论文中出现的主要影像类型。本文选择了在10篇以上的论文中出现的前12种影像类型，并展示在图6中。其中，根据论文的标题、关键词和摘要中是否出现卫星关键词，对被选取和统计的论文数量进行排序。此外，图6还显示了从1985年到2021年的每5~6年间，与各类影像相关的论文数量分布情况。</p> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 6.png" alt="" width="800"/></div> <center>图6. 该领域不同时期的主要卫星影像类型</center> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 7.png" alt="" width="800"/></div> <center>图7. 在不同时期不同类型的云与云阴影检测方法发展情况</center> <p>本文还对不同时期不同类型的云与云阴影检测算法进行了文献分析，结果见图7，可看到基于物理规则的算法因其简单性和效率而成为最受欢迎的云与云阴影检测算法类型，在不同时期均被广泛研究。此外，图7中的结果还表明，基于深度学习的方法作为机器学习算法的一个分支，近年来获得了广泛关注，这得益于深度学习在影像分类等任务中的巨大进步以及大量开源数据集的发布。由于卫星数据源的增加和时间序列影像的广泛使用，基于时相变化的算法在过去一段时间内逐渐受到更多的关注。值得注意的是，基于变分模型的算法在最近几年得到了发展，可以预见，这类算法在多时相影像中的一体化云检测和去除方面将有更广泛的应用潜力。</p> <h4 id="3-问题与前景"><strong>3. 问题与前景</strong></h4> <p>尽管目前用于光学卫星影像的云与云阴影检测算法已经取得了很大的进展，但有些问题仍然没有解决，或者需要更好地解决。这篇综述总结了云与云阴影检测中目前面临的问题，以及在准确性、通用性、效率、时间序列影像处理和应用方面的前景。</p> <h5 id="1云与云阴影检测的共性问题与精度提升"><strong>1）云与云阴影检测的共性问题与精度提升</strong></h5> <p>薄云检测的结果对云检测算法的总体准确性有很大影响。由于下垫面的不同，类似于厚云和晴空地表之间过渡区域的雾或半透明云的大面积的薄云，具有很大的光谱变异性，因此阻碍了其准确的检测。此外，由于其光谱特性与云相似，包括雪/冰、建筑区和高亮的水体在内的高亮地表在云检测中很容易被误检，特别是在有大面积雪/冰覆盖的地区，鉴于除了从大面积云和高亮地表在边缘区域有轻微差异外，很难从其中心区域提取具有辨识性的特征。此外，考虑到影像中云的几何特征各不相同，输入影像的块大小有限，以及深层模型的感受野，基于卷积神经网络的方法不容易将大面积的云与非云的明亮表面完全和彻底地区分开。为了解决这些问题，将面向对象的影像分析和具有空间注意机制的深度模型结合起来，并引入地理信息和额外的辅助数据，可能有利于大面积云的检测和它们与雪的区分。此外，为不同的局部场景构建单独的模型，并学习不同复杂地表的云检测的场景自适应模型，也可能有助于提高准确性。</p> <p>此外，在云阴影检测方面仍有很大的改进空间。例如，广泛使用的Landsat影像的Fmask方法的云阴影检测精度只有70%左右。鉴于云阴影与影像中的云相比通常只占很小的比例，云阴影检测比云检测受到的关注要少。一方面，云阴影很容易与影像中的暗色和低反射率目标（如地形阴影和水体）相混淆，从而使得云阴影的精确检测变得更具有挑战性，特别是对于高空间分辨率的影像，云阴影的特征并不十分明显。云阴影检测的准确性也受到云检测精度，以及基于物理规则的模型在匹配云和其阴影时产生的误差的限制。另一方面，由于受到卫星观测和太阳角度的影响，云阴影在影像中大部分被云遮挡，影像中云阴影的整体面积通常比云小得多，这可能导致云和云阴影样本类别不均衡，在一定程度上降低了基于机器学习算法的云阴影检测精度。在基于深度学习的算法中，云阴影训练样本不足是导致云阴影检测精度低的因素之一。在这方面，鉴于云和云阴影之间的类别不均衡，引入小样本迁移学习将有助于提高云阴影检测的准确性。此外，在多源辅助数据（如DEM）的辅助下，影像中的地形阴影的强度可被估计，并用于减少云阴影的错检。</p> <h5 id="2结合物理模型和深度学习用于云与云阴影的检测和去除"><strong>2）结合物理模型和深度学习用于云与云阴影的检测和去除</strong></h5> <p>基于物理规则和深度学习的算法已被广泛地独立开发用于云与云阴影检测，鉴于其特点和优势，基本上可以分为模型驱动和数据驱动的方法。模型驱动（即基于物理规则和基于变分模型）的方法通常是确定的并基于经验假设，可能难以应对复杂的土地覆盖条件，变分模型的求解效率有待提高。相反，虽然数据驱动（即传统的基于机器学习和基于深度学习）的方法比模型驱动的方法具有更强的特征表达能力，但其性能严重依赖训练数据。考虑到大规模云与云阴影训练样本的获取非常耗时且效率低下，模型驱动和数据驱动方法的结合对于云与云阴影检测来说具有前景，可在降低训练样本需求的同时提升模型性能和效率。在特征和数据方面，物理模型的输出可以作为深度模型的先验知识和输入特征，大气散射规律等物理模型也可以用来模拟云覆盖样本，在一定程度上满足深度模型的样本需求。在方法上，模型驱动（即变分模型）和数据驱动（即深度学习）方法可以以不同的形式结合起来，它们的耦合将结合它们的优势，同时有利于精度和效率的提高。因此，物理模型和深度学习的结合，特别是模型驱动和数据驱动方法的耦合，在云与云阴影检测方面很有前景，值得在未来进一步探索。</p> <p>此外，通常所说的云检测通常不包括对雾等薄云的检测，而是直接进行去雾和薄云去除，以减少雾和薄云的影响。考虑到雾和云都是影响光学卫星影像质量的退化因素，对云的处理通常由三部分组成，包括去雾/薄云去除、云检测和厚云去除，它们通常独立进行或部分结合。在未来，一个具有前景的考虑是结合物理模型和数据驱动方法，实现影像中薄云和厚云的联合估计，并进行综合的薄/厚云去除，以提高影像质量和可用性。特别地，物理模型可以用来模拟大量的雾和云覆盖的影像样本，用于数据驱动方法（如深度学习）的模型训练，以构建一个综合模型用于同时进行影像中薄云和厚云的去除。随着光学卫星影像数量的快速增长，这样的组合和方法将能够为海量影像的高效云处理提供有力支持。</p> <h5 id="3发展多传感器影像云与云阴影检测的统一框架"><strong>3）发展多传感器影像云与云阴影检测的统一框架</strong></h5> <p>由于不同传感器的卫星影像在波段设置和光谱响应方面存在差异，目前大多数云与云阴影检测算法都是针对特定类型的影像开发和应用，从而限制了云与云阴影检测算法对多传感器影像的适用性。鉴于卫星影像数据源的数量不断增加，为以前或新发射卫星的影像开发不同的算法变得效率低下。因此，应开发一个统一的框架来提高云与云阴影检测对多传感器影像的通用性。在这方面，分析多传感器影像的共同的光谱特征和挖掘影像的不变空间特征甚至是时相差异特征，将有利于开发一个统一的框架用于多传感器影像的云与云阴影检测。尽管最近的一些研究试图实现基于深度学习的多传感器云与云阴影检测，但由于模型训练的大量样本需求和不同传感器影像的独特特点，目前基于深度学习的云与云阴影检测算法的应用不能高效地扩展到其他类型的影像。随着深度学习技术的不断进步，基于迁移学习技术（如领域适应）的算法在解决大样本需求方面具有广阔的应用前景，在源域上训练的模型也可以应用于目标域，而不会有太大的精度降低，从而实现多传感器影像的云与云阴影检测目的。此外，通过先进的影像合成技术（如生成对抗网络），基于多个传感器的无云影像模拟云覆盖影像，可以用很少的人力产生大量的训练样本。这样的方法可以满足多传感器模型的训练需求，为构建多传感器影像云与云阴影检测的统一框架提供了新的方案。</p> <h5 id="4基于人工智能的大规模光学卫星数据在线云处理"><strong>4）基于人工智能的大规模光学卫星数据在线云处理</strong></h5> <p>随着大量光学卫星数据的发布，密集的处理需求促使我们开发更有效的在线云检测算法。在线处理平台，如Google Earth Engine (GEE), 亚马逊Web Services和微软Azure，提供了快速访问和在线处理卫星大数据的机会，以支持其广泛的应用。在这种情况下，在线云检测算法对于实现光学卫星影像的近实时预处理至关重要。最近的研究已经提出了基于在线GEE平台的云检测方法，并取得了令人满意的结果。在未来，在线处理平台和人工智能技术的进一步结合将为大规模卫星数据的处理提供一个新的范式，包括但不限于云检测，并实现大规模对地观测数据的高精度和高效应用。</p> <h5 id="5结合云检测去除与时间序列影像分析"><strong>5）结合云检测/去除与时间序列影像分析</strong></h5> <p>时间序列影像在地表的连续监测中发挥着重要作用，然而，云覆盖造成了时间序列影像的信息缺失问题。在这方面，云检测和去除对于构成所需区域的清晰的和无缝的影像都至关重要，特别是多云地区和其它降水丰富的地区。鉴于多时相云去除通常利用同一地区的相邻时相影像的辅助信息来重建被云覆盖的区域，在以前的大多数研究中，云检测和云去除被当作独立的过程。因此，集成的多时相云检测和去除将提高处理效率，减少误差积累。一方面，时间序列影像中的时相特征有利于提高云与云阴影检测的准确性，特别是在复杂和高亮的地表区域。另一方面，时间序列影像提供了更长、更连续的观测信息，也有利于云覆盖区域的精确重建。在云检测和云去除的结合方面，时间序列模型和变分模型已经证明了它们的应用潜力，而更先进的技术，如深度学习，值得进一步探索。</p> <h4 id="4-结论"><strong>4. 结论</strong></h4> <p>云与云阴影检测是卫星影像预处理和应用的一个重要步骤，也一直是光学遥感领域的一个重要话题。本综述通过文献调查研究了该领域的发展趋势，从特征、算法、验证等方面回顾了云与云阴影检测的研究，总结了存在的问题，并提出了我们对该领域未来发展的展望。可以得出这样的结论：来自辅助数据的光谱、空间、时相和多源特征的结合，已经被证明可以有效地缓解云与云阴影的误检和遗漏问题。就只使用影像本身的信息而言，光谱-空间特征和光谱-空间-时相特征是最有希望实现高精度云与云阴影检测的两类特征。特别地，基于深度学习的方法在有足够训练数据的支持下，在云与云阴影检测方面已被证明比其他类型的算法更有优势。由于获取人工标记的云掩膜很耗时，与光学影像共址的LiDAR/雷达数据和地面相机数据可作为替代来源。通过提高复杂情形下的准确性，以及通过开发一个统一的框架提高跨传感器的通用性，可以进一步改进云与云阴影检测算法。在未来，在研究物理模型和深度学习的结合、探索薄/厚云检测/去除的整合、开发大规模卫星数据的人工智能在线处理方法等方面需要进一步研究，这将促进光学卫星影像的高效处理和精细应用。</p> <h4 id="主要作者简介"><strong>主要作者简介：</strong></h4> <p><strong>李志伟</strong>，博士，香港理工大学土地测量及地理资讯学系研究助理教授。主要研究兴趣为多云多雨环境遥感，研究方向包括卫星影像云检测与去除，多源数据融合，土地覆盖制图，洪水监测等。个人主页：https://zhiweili.net/。</p> <p><strong>沈焕锋</strong>，武汉大学资源与环境科学学院教授、院长，国家级高层次人才入选者者，主要研究方向为遥感数据质量改善、多源感知数据融合、地学智能等。</p> <p><strong>翁齐浩</strong>，欧洲科学院外籍院士、 美国科学促进会（AAAS）‍会士、电气与电子工程师协会（IEEE）会士、美国地理学会（AAG）会士、美国摄影测量与遥感学会（ASPRS）会士、亚太人工智能学会（AAIA）会士，现任香港理工大学地理信息学和人工智能讲座教授、曾任美国印第安纳州立大学城市与环境变化中心主任和教授和美国航天局高级研究员。现为地球观测组织的全球城市观测和信息系统项目负责人并任《国际摄影测量与遥感学会期刊》（ISPRS J P&amp;RS）主编。翁教授的研究侧重于遥感科学和技术在城市环境与生态系统中的应用、土地利用和土地覆盖的变化和城市化的环境效应等。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Li Z. et al., 2022, ISPRS J. Photogramm. Remote Sens.]]></summary></entry><entry><title type="html">Cloud and cloud shadow detection for optical satellite imagery - Features, algorithms, validation, and prospects</title><link href="https://zhiweili.net//blog/2022/cloud-detection-review/" rel="alternate" type="text/html" title="Cloud and cloud shadow detection for optical satellite imagery - Features, algorithms, validation, and prospects"/><published>2022-07-05T00:00:00+00:00</published><updated>2022-07-05T00:00:00+00:00</updated><id>https://zhiweili.net//blog/2022/cloud-detection-review</id><content type="html" xml:base="https://zhiweili.net//blog/2022/cloud-detection-review/"><![CDATA[<p>Li, Z., Shen, H., Weng, Q., Zhang, Y., Dou, P., Zhang, L. (2022). Cloud and cloud shadow detection for optical satellite imagery: Features, algorithms, validation, and prospects. ISPRS Journal of Photogrammetry and Remote Sensing, 188, 89–108. [<a href="https://doi.org/10.1016/j.isprsjprs.2022.03.020">HTML</a>] <a href="https://zhiweili.net/assets/pdf/2022.6_ISPRS%20P&amp;RS_Cloud%20and%20cloud%20shadow%20detection%20for%20optical%20satellite%20imagery%EF%BC%9AFeatures,%20algorithms,%20validation,%20and%20prospects.pdf">[PDF]</a> <a href="https://github.com/dr-lizhiwei/OpenSICDR">[Project]</a></p> <h4 id="abstract"><strong>Abstract</strong></h4> <p>The presence of clouds prevents optical satellite imaging systems from obtaining useful Earth observation information and negatively affects the processing and application of optical satellite images. Therefore, the detection of clouds and their accompanying shadows is an essential step in preprocessing optical satellite images and has emerged as a popular research topic in recent decades due to the interest in image time series analysis and remote sensing data mining. This review first analyzes the trends of the field, summarizes the progress and achievements in the cloud and cloud shadow detection methods in terms of features, algorithms, and validation of results, and then discusses existing problems, and provides our prospects at the end. We aim at identifying the emerging research trends and opportunities, while providing guidance for selecting the most suitable methods for coping with cloud contaminated problems faced by optical satellite images, an extremely important issue for remote sensing of cloudy and rainy areas. In the future, expected improvements in accuracy and generalizability, the combination of physical models and deep learning, as well as artificial intelligence and online big data processing platforms will be able to further promote processing efficiency and facilitate applications of image time series. In addition, this review collects the latest open-source tools and datasets for cloud and cloud shadow detection and launches an online project (Open Satellite Image Cloud Detection Resources, i.e., OpenSICDR) to share the latest research outputs (<a href="https://github.com/dr-lizhiwei/OpenSICDR">https://github.com/dr-lizhiwei/OpenSICDR</a>).</p> <h4 id="1-introduction"><strong>1.</strong> <strong>Introduction</strong></h4> <p>Over the past decades, with the release of massive amounts of optical satellite data and the continuous introduction of new data sources, many studies have focused on cloud and cloud shadow detection (CCS) detection for images taken by different sensors, and many CCS detection methods have been developed. Although the CCS detection literature has been reviewed in previous studies, they mainly focus on the categorization of methodologies, cloud measuring equipment, and forms of CCS detection results. To further conduct a systematic summary of the current achievements and challenges in this field, this study comprehensively reviews the CCS detection literature from the features, algorithms, and validation perspectives as shown in Fig. 1. Different CCS detection methods are reviewed separately from both the features and algorithms perspectives given that algorithms of different categories may achieve CCS detection by using the same type of features and because algorithms of the same category may also accept different types of features. This review also summarizes the main types of CCS detection results and their validation.</p> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review//Fig. 1.png" alt="" width="1000"/></div> <center>Fig. 1. Cloud and cloud shadow detection in terms of features, algorithms, and validation.</center> <h4 id="2-literature-analysis"><strong>2. Literature analysis</strong></h4> <p>We have conducted a literature survey with Scopus (www.scopus.com) on the topic of cloud and cloud shadow detection for optical satellite imagery, and the search keywords include <em>cloud/cloud shadow AND detection/masking/extraction/screening/identification</em>, which are limited to title, keywords, and abstract of the journal articles in English. Based on search results as of December 1, 2021, a total of 1425 journal papers were returned from the Scopus database. Eventually, there are 504 papers selected for the literature analysis after manually excluding irrelevant articles. Noted that articles related to cloud classification which further classify clouds into different types according to cloud phase and altitude are not discussed and included in the literature survey. Besides, to ensure the high quality of the papers used for literature analysis, only articles published in formal journals were selected, and each paper was manually checked and confirmed to make sure that it fits the topic of this review. As shown in Fig. 2, the survey result suggests that there is a general increasing trend in the number of published papers and their citations over the past 37 years from 1985 to 2021, especially in the latest decade, which indicates extensive attention was paid to this field recently. Besides, the major countries/region, institutions, and journals in the field are listed in Fig. 2-5.</p> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 2.png" alt="" width="600"/></div> <center>Fig. 2. The number of papers and citations on cloud and cloud shadow detection, 1985–2021.</center> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 3.png" alt="" width="600"/></div> <center>Fig. 3. Major countries/regions (published &gt; 10 journal papers) in the field.</center> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 4.png" alt="" width="600"/></div> <center>Fig. 4. Major institutions (published &gt; 10 journal papers) in the world.</center> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 5.png" alt="" width="600"/></div> <center>Fig. 5. Major journals (published &gt; 10 journal papers) in the field.</center> <p>Moreover, the number of papers with different types of satellite images was counted to determine the major types of images that occurred in these 504 papers. The top twelve types of images occurring in &gt;10 papers are selected and shown in Fig. 6, which are sorted by the number of papers that are selected and counted according to whether the satellite keyword occurs in the title, keywords, and abstract of the paper. Fig. 6 also shows the distributions of the number of papers relevant to each type of image over the past each 5–6 years periods from 1985 to 2021.</p> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 6.png" alt="" width="800"/></div> <center>Fig. 6. Major types of satellite images over different periods in the field.</center> <div align="center"><img src="/assets/img/blogs/2022_cloud detection review/Fig. 7.png" alt="" width="800"/></div> <center>Fig. 7. Types of cloud and cloud shadow detection algorithms developed in different periods.</center> <p>Literature analysis was also conducted on different types of CCS detection algorithms over different periods, the results shown in Fig. 7 confirmed that physical-rule algorithms benefiting from their simplicity and efficiency are the most popular type of CCS detection algorithms, which have been heavily studied at different periods. In addition, the results shown in Fig. 7 also indicated that DL-based methods as a branch of ML-based algorithms have gained much attention in recent years, benefiting from the great progress of DL in tasks such as image classification and the release of a large number of open-source datasets. Moreover, temporal-changes based algorithms have gradually received more attention in the past periods owing to the increase in satellite data sources and the widespread use of image time series. Notably, variational-model based algorithms have been developed in recent years, and it can be expected that such types of algorithms will have broader application potentials for integrated cloud detection and removal in multi-temporal images.</p> <h4 id="3-problems-and-prospects"><strong>3. Problems and prospects</strong></h4> <p>Although the current CCS detection algorithms for optical satellite images have witnessed much progress, some problems remain unsolved or need to be better resolved. This review summarizes the current problems faced in CCS detection and prospects in terms of accuracy, generalizability, efficiency, and image time series processing and applications.</p> <h5 id="1-common-problems-and-accuracy-improvement-for-ccs-detection"><strong>1) Common problems and accuracy improvement for CCS detection</strong></h5> <p>The results of thin cloud detection have a significant impact on the accuracy of different cloud detection algorithms. Large-area thin clouds that are similar to haze or translucent clouds in the transition region between thick clouds and the clear sky surface have large variability due to different underlying surfaces, hence impeding an accurate detection. Moreover, high bright surfaces, including snow/ice, built-up areas, and bright water bodies, can be easily misidentified in cloud detection due to their spectral properties similar to clouds, especially in areas with large-area snow/ice, given the difficulty in extracting identifiable features from the central region of large clouds and bright surfaces but with slight differences in the edge regions. Moreover, given the varying geometric characteristics of clouds in an image, the limited block size of the input image and the receptive field of the deep model, CNN-based algorithms cannot easily separate large-area clouds from non-cloud bright surfaces completely and comprehensively. To address these problems, the combination of object-oriented image analysis (OBIA) and deep models with spatial attention mechanisms and the introduction of geographical information and additional auxiliary data may benefit the detection of large-area clouds and their discrimination from snow. In addition, constructing individual models for different local scenes and learning scene adaptive models for cloud detection in different complex surfaces may also help boost accuracy.</p> <p>In addition, there is still much room for improvement in cloud shadow detection. For example, the cloud shadow accuracy of the widely used Fmask algorithm for Landsat images is only about 70%. Cloud shadow detection has received less attention than cloud detection given that cloud shadows usually account for only a small percentage compared with clouds in images. On the one hand, cloud shadows are easily confused with dark and low-reflectivity targets in images, such as terrain shadows and water bodies, thereby challenging the accurate detection of cloud shadow, especially for high spatial resolution images in which the features of cloud shadow are not sufficiently significant. The cloud shadow detection accuracy is also limited by the accuracy of cloud detection and the errors generated by the physical-rule based models when matching clouds with their shadows. On the other hand, the overall area of cloud shadows in the image is usually much smaller than that of clouds due to the fact that most cloud shadows are obscured by clouds influenced by satellite viewing and solar angles, which may lead to sample categories imbalance and reduce the accuracy of cloud shadow detection for machine-learning based algorithms to some degree. The insufficient cloud shadow training samples in DL-based algorithms is one factor that leads to poor cloud shadow detection accuracy. In this regard, given the category imbalance between clouds and cloud shadows, introducing small sample transfer learning will help improve cloud shadow detection accuracy. Moreover, with the aid of multi-source auxiliary data (e.g., DEM), terrain shadows in images can be predicted and used to reduce the misidentification of cloud shadows.</p> <h5 id="2-combination-of-physical-model-and-deep-learning-for-ccs-detection-and-removal"><strong>2) Combination of physical model and deep learning for CCS detection and removal</strong></h5> <p>Physical-rule and DL-based algorithms have been widely and individually developed for CCS detection, which can be essentially categorized as model-driven and data-driven methods given their characteristics and advantages, respectively. The model-driven (i.e. physical-rule based and variational-model based) methods are usually definite and are construed based on the empirical assumptions, which may be difficult to cope with complex land cover conditions and the solving efficiency of variational models needs to be improved. On the contrary, while the data-driven (i.e. traditional machine-learning based and DL-based) methods have more strong feature representation capabilities than model-driven methods, their performances rely heavily on training data. Considering that the acquisition of large-scale CCS training samples is time-consuming and inefficient as there are many different types of images, the combination of model-driven and data-driven methods will be promising for CCS detection, and boosting model performance and efficiency while reducing the need for training samples. In terms of features and data, the output of the physical model can be used as the prior knowledge and input features of the deep model, and the physical model such as atmospheric scattering law can also be used to stimulate cloud samples and to meet the sample requirements of the deep model to some degree. In terms of methods, model-driven (i.e. variational model) and data-driven (i.e. deep learning) methods can be combined in different forms, their coupling will combine their strengths and benefit the improvements of accuracy and efficiency simultaneously. Therefore, the combination of the physical model and DL, especially the coupling of model-driven and data-driven methods, are promising for CCS detection and worths further exploration in the future.</p> <p>In addition, the commonly called cloud detection usually does not include the detection of thin clouds like haze, instead, direct dehazing and thin cloud removal is performed to reduce the effect of haze and thin clouds. Considering that both haze and clouds are degrading factors affecting the quality of optical satellite images, the processing of clouds usually consists of three parts, including dehazing/thin cloud removal, cloud detection, and thick cloud removal, which are usually performed independently or partially coupled. In the future, a promising consideration is to combine physical models and data-driven methods to achieve a joint estimation of cloud thickness for both thin and thick clouds, and conduct an integrated thin/thick cloud removal to improve the image quality and usability. In particular, physical models can be used to simulate a large number of hazy and cloud-covered image samples for model training of data-driven methods, such as deep learning, to construct an integrated model for simultaneous thin and thick cloud removal in images. With the rapidly growing amount of optical satellite images, such a combination and method will be able to provide strong support for efficient cloud processing of massive images.</p> <h5 id="3-development-of-a-unified-framework-for-ccs-detection-for-multi-sensor-images"><strong>3) Development of a unified framework for CCS detection for multi-sensor images</strong></h5> <p>Due to the differences in band settings and spectral responses of satellite images of different sensors, most of the current CCS detection algorithms have been developed and applied to specific types of images, thereby limiting the applicability of CCS detection algorithms for multi-sensor images. Given the increasing number of satellite image data sources, developing different algorithms for images of previously or newly launched satellites becomes inefficient. Therefore, a unified framework should be developed to boost the generalizability of CCS detection for images of multiple sensors. In this regard, analyzing common spectral characteristics and mining the invariant spatial features and even temporal difference features of images will benefit the development of a unified framework for the CCS detection of multi-sensor images. Although several recent studies have attempted to achieve multi-sensor CSS detection based on DL, the application of current DL-based CCS detection algorithms cannot be effectively extended to other types of images due to the large sample requirements for model training and the unique characteristics of images from different sensors. With the continuous advancements of DL techniques, algorithms supported by transferring learning techniques, such as domain adaptation, have promising applications in addressing large sample requirements, in which models trained on the source domain can also be applied to the target domain without much accuracy reduction, and thus achieve the goal of CCS detection for multi-sensor images. In addition, simulating cloudy images based on clear images of multiple sensors through advanced image synthesis techniques, such as GAN, can generate a large number of training samples with very little human effort. Such an approach can be used to meet the training requirements of multi-sensor models, and provide a new scheme for the construction of a unified framework for CCS detection in multi-sensor images.</p> <h5 id="4-ai-enabled-online-cloud-processing-for-large-scale-optical-satellite-data"><strong>4) AI-enabled online cloud processing for large-scale optical satellite data</strong></h5> <p>With the release of a large amount of optical satellite data, the dense processing requirements motivate us to develop more effective online cloud detection algorithms. Online processing platforms, such as Google Earth Engine (GEE), Amazon Web Services, and Microsoft Azure, provide opportunities to quickly access and process big satellite data online to support their wide range of applications. In this case, online cloud detection algorithms are crucial to achieving a near-real-time pre-processing of optical satellite images. Recent studies have investigated cloud detection in online GEE platforms and achieved satisfactory results. In the future, the further combination of online processing platforms and artificial intelligence (AI) technologies will provide a new paradigm for the processing of large-scale satellite data, including but not limited to cloud detection, and enable the high-precision and efficient application of large-scale Earth observation data.</p> <h5 id="5-integration-of-cloud-detectionremoval-with-image-time-series-analysis"><strong>5) Integration of cloud detection/removal with image time series analysis</strong></h5> <p>Image time series play an important role in the long-term monitoring of the Earth surface, however, cloud coverage causes the problem of information missing in image time series. In this regard, cloud detection and removal are both essential for the composition of clean and seamless images of desired areas, especially cloudy areas and other areas with abundant rainfall. Given that multi-temporal cloud removal usually utilizes auxiliary information from the adjacent temporal images of the same areas to reconstruct the cloud-covered areas, cloud detection and cloud removal are treated as individual processes in most previous studies. Therefore, the integrated multi-temporal cloud detection and removal will improve processing efficiency and reduce error accumulation. On the one hand, the temporal features in image time series benefit the accuracy improvement of CCS detection, especially in complex and bright land surfaces. On the other hand, image time series, which provide longer and more continuous observation information, also benefit the accurate reconstruction of cloud-covered areas. In terms of the integration of cloud detection and cloud removal, time series models and variational models have demonstrated their application potentials, and more advanced techniques, such as DL, warrant further exploration.</p> <h4 id="4-conclusions"><strong>4. Conclusions</strong></h4> <p>CCS detection is an essential step in satellite image preprocessing and applications and has remained an important topic in the field of optical remote sensing. This review has examined the trends in the field through a literature survey, reviewed the CCS detection studies from the features, algorithms, and validation aspects and summarized the existing problems, and provided our prospects for future development. It can be concluded that the combination of spectral, spatial, temporal, and multi-source features from auxiliary data has been proved effective to alleviate the commission and omission problems of CCS. In terms of using only the information from the images themselves, spectral-spatial features and spectral-spatial-temporal features are the two most promising types of features that enable high-precision CCS detection. Particularly, DL-based methods have been demonstrated their superiority over other types of algorithms in CCS detection with the support of sufficient training data. Collocated LiDAR/radar data and ground-based camera data were alternative sources for validation, as the acquisition of manually labeled masks was time-consuming. Further improvement in CCS detection algorithms can be made by improving accuracy in complex conditions, and by boosting the cross-sensor generalizability by developing a unified framework. Further research is warranted in investigating the combination of physical model and deep learning, exploring the integration of thin/thick cloud detection/removal, and developing AI-enabled online processing methods for large-scale satellite data, which will facilitate efficient processing and fine applications of optical satellite imagery.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Li Z. et al., 2022, ISPRS J. Photogramm. Remote Sens.]]></summary></entry></feed>